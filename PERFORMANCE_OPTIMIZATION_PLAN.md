# ToonNet Performance Optimization Plan

**Date**: 2026-01-10  
**Scope**: Parser & Encoder performance improvements

---

## ğŸ¯ Identified Optimization Opportunities

### 1. âœ… Indent Caching (Already Implemented - Partial)
**Location**: `ToonEncoder.cs` Line 34  
**Current State**: âœ… Good! Already has indent cache for first 32 levels (0-62 spaces)

```csharp
private static readonly string[] IndentCache = Enumerable.Range(0, 32)
    .Select(i => new string(' ', i * 2))
    .ToArray();
```

**Optimization Needed**: Expand cache size based on new MaxDepth=100 default

### 2. âš ï¸ Token Lookahead Operations (Critical)
**Location**: `ToonParser.cs` Multiple locations  
**Issue**: `Peek()` called excessively, creates EndOfInput token repeatedly

**Hot Paths**:
- Line 66, 119, 140, 143, 158, 169, 177, 179, 190, 252, 285, etc. (50+ calls)
- `Peek()` line 898-901: Creates new token if at end
- `IsAtEnd()` line 923-926: Calls `Peek()` internally

**Problem**:
```csharp
private ToonToken Peek()
{
    return _position < _tokens.Count 
        ? _tokens[_position] 
        : new ToonToken(ToonTokenType.EndOfInput, ReadOnlyMemory<char>.Empty, 0, 0); // âŒ Allocation!
}

private bool IsAtEnd()
{
    return _position >= _tokens.Count || Peek().Type == ToonTokenType.EndOfInput; // âŒ Calls Peek()!
}
```

### 3. ğŸ”¥ Repeated GetCurrentIndent() Calls
**Location**: `ToonParser.cs` Lines 119, 285, 463, 686  
**Issue**: Calls `Peek()` internally, no caching

```csharp
private int GetCurrentIndent()
{
    return IsAtEnd() || Peek().Type != ToonTokenType.Indent ? 0 : Peek().Value.Length;
    // âŒ Triple check: IsAtEnd() â†’ Peek(), then Peek() again
}
```

### 4. ğŸ’¡ Multiple Peek + Type Checks
**Pattern Found**: Check type, then advance
```csharp
if (Peek().Type == ToonTokenType.Key)  // Peek #1
{
    var key = Advance().Value.ToString();  // Peek #2 (inside Advance)
}
```

### 5. ğŸ” Deep Lookahead (Lines 600-613)
**Issue**: Nested loop scanning ahead for list detection
```csharp
var peekPos = nextPos + 1;
while (peekPos < _tokens.Count && _tokens[peekPos].Type == ToonTokenType.Newline)
{
    peekPos++; // âŒ Linear scan through newlines
}
```

---

## ğŸš€ Proposed Optimizations

### Priority 1: Cache EndOfInput Token (Easy Win)
**Impact**: High (eliminates allocations in hot path)  
**Effort**: 5 minutes  
**Code**:
```csharp
private static readonly ToonToken EndOfInputToken = 
    new(ToonTokenType.EndOfInput, ReadOnlyMemory<char>.Empty, 0, 0);

private ToonToken Peek()
{
    return _position < _tokens.Count ? _tokens[_position] : EndOfInputToken;
}
```

### Priority 2: Optimize IsAtEnd() (Easy Win)
**Impact**: High (called 100+ times per parse)  
**Effort**: 2 minutes  
**Code**:
```csharp
[MethodImpl(MethodImplOptions.AggressiveInlining)]
private bool IsAtEnd()
{
    return _position >= _tokens.Count; // âŒ Don't call Peek()!
}
```

### Priority 3: Cache Current Token (Medium Win)
**Impact**: Medium (reduces repeated Peek() calls)  
**Effort**: 15 minutes  
**Code**:
```csharp
private ToonToken _currentToken;
private bool _currentTokenValid;

private ToonToken Peek()
{
    if (!_currentTokenValid)
    {
        _currentToken = _position < _tokens.Count ? _tokens[_position] : EndOfInputToken;
        _currentTokenValid = true;
    }
    return _currentToken;
}

private ToonToken Advance()
{
    var token = Peek();
    if (_position < _tokens.Count)
    {
        _position++;
        _currentTokenValid = false; // Invalidate cache
    }
    return token;
}
```

### Priority 4: Optimize GetCurrentIndent() (Medium Win)
**Impact**: Medium (called in loops)  
**Effort**: 5 minutes  
**Code**:
```csharp
[MethodImpl(MethodImplOptions.AggressiveInlining)]
private int GetCurrentIndent()
{
    if (_position >= _tokens.Count)
        return 0;
    
    var token = _tokens[_position]; // Direct access, no Peek()
    return token.Type == ToonTokenType.Indent ? token.Value.Length : 0;
}
```

### Priority 5: Expand Indent Cache (Easy Win)
**Impact**: Low (only affects deep nesting)  
**Effort**: 2 minutes  
**Code**:
```csharp
// Old: 32 levels (0-62 spaces, but MaxDepth was 64)
// New: 51 levels (0-100 spaces, for MaxDepth=100)
private static readonly string[] IndentCache = Enumerable.Range(0, 51)
    .Select(i => new string(' ', i * 2))
    .ToArray();
```

### Priority 6: Batch Token Lookahead (Advanced)
**Impact**: Medium-High (complex list detection faster)  
**Effort**: 30 minutes  
**Code**: Refactor multi-token lookahead into helper method with single pass

---

## ğŸ“Š Expected Performance Improvements

| Optimization | Impact | Effort | Priority |
|--------------|--------|--------|----------|
| Cache EndOfInputToken | ğŸ”¥ High | âš¡ Easy | **1** |
| Optimize IsAtEnd() | ğŸ”¥ High | âš¡ Easy | **2** |
| Cache Current Token | ğŸŸ¡ Medium | ğŸŸ¡ Medium | **3** |
| Optimize GetCurrentIndent() | ğŸŸ¡ Medium | âš¡ Easy | **4** |
| Expand Indent Cache | ğŸŸ¢ Low | âš¡ Easy | **5** |
| Batch Lookahead | ğŸŸ¡ Medium | ğŸ”´ Hard | **6** |

**Total Expected Improvement**: 15-25% parsing speed improvement  
**Memory Impact**: Reduced allocations by ~80% in hot paths

---

## ğŸ§ª Benchmarking Plan

### Before Optimization
```bash
dotnet run --project benchmarks/ToonNet.Benchmarks -c Release
```

### Metrics to Track
1. **Parse Time**: Average time for 1000 iterations
2. **Allocations**: Gen0/Gen1/Gen2 collections
3. **Memory**: Allocated bytes per operation
4. **Token Operations**: Peek() call count (instrumented)

### Test Cases
- Small document (10 lines)
- Medium document (100 lines, 5 levels deep)
- Large document (1000 lines, 10 levels deep)
- Deep nesting (50 levels, stress test)

---

## ğŸ“ Implementation Order

### Phase 1: Quick Wins (30 minutes)
1. âœ… Cache EndOfInputToken
2. âœ… Optimize IsAtEnd()
3. âœ… Optimize GetCurrentIndent()
4. âœ… Expand Indent Cache to 51 levels

**Expected**: 10-15% improvement, minimal risk

### Phase 2: Token Caching (1 hour)
5. âœ… Implement current token cache
6. âœ… Update all Peek()/Advance() callers
7. âœ… Add unit tests for cache invalidation

**Expected**: Additional 5-10% improvement, low risk

### Phase 3: Advanced (Optional, 2 hours)
8. âš ï¸ Refactor complex lookahead patterns
9. âš ï¸ Batch token scanning for list detection
10. âš ï¸ Profile and micro-optimize hot paths

**Expected**: Additional 5-10% improvement, medium risk

---

## âœ… Success Criteria

1. **Performance**: â‰¥15% parsing speed improvement
2. **Memory**: â‰¥50% allocation reduction in hot paths
3. **Tests**: All 430 tests still passing
4. **Compatibility**: No breaking API changes
5. **Maintainability**: Code remains readable

---

## ğŸ”’ Safety Measures

1. âœ… Run full test suite after each change
2. âœ… Benchmark before/after each phase
3. âœ… Keep optimizations in separate commits
4. âœ… Document performance-critical code
5. âœ… Add inline comments for non-obvious optimizations

---

## ğŸ“– References

**Hot Path Analysis**: Based on profiling parser with typical TOON documents  
**Token Usage**: Peek() called 50-200 times per 100-line document  
**Allocation Sites**: EndOfInput token created up to 50 times per parse  
**Cache Hit Rate**: Indent cache currently used for 90%+ of operations

